# -*- coding: utf-8 -*-
"""Bert LLM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_Q8tazQoxRm5ujAmIr6WWTNX84NgkjYX
"""

import os
os.environ["WANDB_DISABLED"] = "true"
os.environ["TOKENIZERS_PARALLELISM"] = "false"

import numpy as np
import torch
print(f"NumPy: {np.__version__}")
print(f"PyTorch: {torch.__version__}")
print(f"CUDA Available: {torch.cuda.is_available()}")

# Step 2: Robust Data Loading
# ---------------------------
from datasets import load_dataset, Dataset, DatasetDict
import pandas as pd
from io import StringIO
import requests


def load_ag_news():
    sources = [
        lambda: load_dataset("ag_news"),
        lambda: pd.read_csv("https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv", header=None, names=["label", "title", "text"]),
        lambda: pd.read_csv(StringIO(requests.get("https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv").text), header=None, names=["label", "title", "text"])
    ]
    for source in sources:
        try:
            data = source()
            if isinstance(data, pd.DataFrame):
                return {"train": Dataset.from_pandas(data)}
            return data
        except Exception:
            continue
    raise Exception("All data sources failed")

# Load dataset
raw_dataset = load_ag_news()
if isinstance(raw_dataset, dict) and "train" in raw_dataset:
    raw_dataset["train"] = raw_dataset["train"].map(lambda x: {"label": x["label"] - 1})
    if "test" in raw_dataset:
        raw_dataset["test"] = raw_dataset["test"].map(lambda x: {"label": x["label"] - 1})
else:
    raw_dataset = raw_dataset.map(lambda x: {"label": x["label"] - 1})

# Reduce dataset size for faster training/debugging
MAX_SAMPLES = 20000
raw_dataset["train"] = raw_dataset["train"].shuffle(seed=42).select(range(MAX_SAMPLES))

# Ensure train/test split
split_dataset = raw_dataset["train"].train_test_split(test_size=0.1, seed=42)
dataset = DatasetDict({
    "train": split_dataset["train"],
    "test": split_dataset["test"]
})

print("\nData loaded successfully!")
print(f"Training samples: {len(dataset['train'])}")
print(f"Test samples: {len(dataset['test'])}")
print(f"First sample: {dataset['train'][0]}")

# Step 3: Tokenization
# ---------------------------
from transformers import BertTokenizer

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

def tokenize_function(examples):
    return tokenizer(
        examples["text"],
        padding="max_length",
        truncation=True,
        max_length=128
    )

tokenized_datasets = {
    "train": dataset["train"].map(tokenize_function, batched=True),
    "test": dataset["test"].map(tokenize_function, batched=True)
}

# Step 4: Model Setup
# ---------------------------
from transformers import BertForSequenceClassification

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = BertForSequenceClassification.from_pretrained(
    'bert-base-uncased',
    num_labels=4,
    id2label={0: "World", 1: "Sports", 2: "Business", 3: "Sci/Tech"}
).to(device)

print(f"\nModel loaded on {device}")

# Step 5: Training Setup
# ---------------------------
from transformers import Trainer, TrainingArguments
from sklearn.metrics import accuracy_score
import transformers

print(f"Transformers version: {transformers.__version__}")

# Temporarily removing evaluation_strategy to diagnose the issue
training_args = TrainingArguments(
    output_dir="./results",
    # evaluation_strategy="epoch", # Removed for debugging
    learning_rate=2e-5,
    per_device_train_batch_size=4,
    per_device_eval_batch_size=4,
    num_train_epochs=3,
    weight_decay=0.01,
    logging_dir="./logs",
    logging_strategy="epoch",
    save_strategy="no",
    report_to="none",
    load_best_model_at_end=False,
    no_cuda=not torch.cuda.is_available()
)

def compute_metrics(p):
    preds = p.predictions.argmax(-1)
    return {
        "accuracy": accuracy_score(p.label_ids, preds)
    }

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["test"],
    compute_metrics=compute_metrics,
)

# Step 6: Training & Evaluation
# ---------------------------
print("\nStarting training...")
try:
    trainer.train()
    results = trainer.evaluate()
    print(f"\nFinal Evaluation - Accuracy: {results['eval_accuracy']:.4f}, Loss: {results['eval_loss']:.4f}")
except Exception as e:
    print(f"\nTraining error: {e}")
    if "CUDA" in str(e):
        print("Trying CPU fallback...")
        device = torch.device("cpu")
        model = model.to(device)
        trainer = Trainer(
            model=model,
            args=TrainingArguments(
                output_dir="./results_cpu",
                evaluation_strategy="epoch",
                learning_rate=2e-5,
                per_device_train_batch_size=2,
                num_train_epochs=3,
                no_cuda=True
            ),
            train_dataset=tokenized_datasets["train"],
            eval_dataset=tokenized_datasets["test"],
            compute_metrics=compute_metrics,
        )
        trainer.train()
        results = trainer.evaluate()
        print(f"\nFinal Evaluation (CPU) - Accuracy: {results['eval_accuracy']:.4f}, Loss: {results['eval_loss']:.4f}")

# Step 7: Prediction
# ---------------------------
if 'trainer' in locals():
    def predict(text):
        inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True).to(device)
        with torch.no_grad():
            logits = model(**inputs).logits
        return model.config.id2label[logits.argmax().item()]

    test_samples = [
        "Stock markets reached record highs today",
        "The national football team won the championship",
        "Scientists discovered a new species in the Amazon",
        "Stock markets reached record highs today",
    "The national football team won the championship",
    "Scientists discovered a new species in the Amazon",
    "Apple unveiled a new AI-powered iPhone at its annual event",
    "The prime minister met with world leaders to discuss climate change",
    "NASA successfully landed a rover on Mars",
    "The basketball finals drew record viewership numbers",
    "Banking sector shows strong growth despite economic concerns",
    "Researchers are testing a new vaccine for malaria",
    "Olympic games are set to begin in Paris next month"
    ]

    print("\nTest Predictions:")
    for text in test_samples:
        print(f"{text[:50]}... â†’ {predict(text)}")

    model.save_pretrained("./ag_news_model")
    tokenizer.save_pretrained("./ag_news_model")
    print("\nModel saved successfully!")
else:
    print("Training failed - cannot evaluate")

